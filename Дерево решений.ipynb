{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class RFClassifier:\n",
    "\n",
    "    def __init__(self, max_features=None,\n",
    "                 n_trees=2,\n",
    "                 min_leaf=1,\n",
    "                 max_depth=np.inf,\n",
    "                 inf_value_type=\"Gini\",\n",
    "                 oob_vote: float = None,\n",
    "                 random_state=None):\n",
    "\n",
    "        self.n_trees = n_trees\n",
    "        self.min_leaf = min_leaf\n",
    "        self.inf_value_type = inf_value_type\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.oob_vote = oob_vote\n",
    "\n",
    "        self.prediction = None\n",
    "        self.y_proba = None\n",
    "        self.proba_data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.forest_pred = []\n",
    "        self.forest_proba = []\n",
    "        self.forest_list_to_predict = []\n",
    "        self.oob_idx = []\n",
    "        self.oob_scores_list = []\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_num(y_list):\n",
    "        num = Counter(y_list)\n",
    "        return dict(num)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bootstrap_idx(n_samples, rdm):\n",
    "        rng = np.random.RandomState(rdm)\n",
    "        indexes = rng.randint(0, n_samples - 1, size=n_samples)\n",
    "        return indexes\n",
    "\n",
    "    def get_subsample(self, n_features, rdm):\n",
    "        rng = np.random.RandomState(rdm)\n",
    "        if self.max_features is None:\n",
    "            self.max_features = int(np.sqrt(n_features))\n",
    "        subsample = rng.choice(\n",
    "            n_features, self.max_features, replace=False)\n",
    "\n",
    "        return subsample\n",
    "\n",
    "    def get_informative_value(self, y_list):\n",
    "        labels_dict = self.get_label_num(y_list)\n",
    "\n",
    "        if self.inf_value_type == \"Gini\":\n",
    "            impurity = 1\n",
    "            for label in labels_dict:\n",
    "                p_label = labels_dict[label] / len(y_list)\n",
    "                impurity -= p_label ** 2\n",
    "            return impurity\n",
    "\n",
    "        if self.inf_value_type == \"Shannon\":\n",
    "            entropy = 0\n",
    "            for label in labels_dict:\n",
    "                p_label = labels_dict[label] / len(y_list)\n",
    "                entropy -= p_label * (0 if (p_label == 0)\n",
    "                                      else np.log2(p_label))\n",
    "            return entropy\n",
    "\n",
    "    def merit_functional(self, true_labels, false_labels, current_informative_value):\n",
    "\n",
    "        p = (true_labels.shape[0]) / \\\n",
    "            ((true_labels.shape[0]) + (false_labels.shape[0]))\n",
    "        quality = current_informative_value - p * self.get_informative_value(true_labels) - \\\n",
    "                  (1 - p) * self.get_informative_value(false_labels)\n",
    "        return quality\n",
    "\n",
    "    def find_best_split(self, X, y, subsample):\n",
    "\n",
    "        current_informative_value = self.get_informative_value(y)\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        for index in subsample:\n",
    "            t_values = set(X[:, index])\n",
    "\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self.data_split(\n",
    "                    X, y, index, t)\n",
    "                if len(true_data) < self.min_leaf or len(false_data) < self.min_leaf:\n",
    "                    continue\n",
    "\n",
    "                current_quality = self.merit_functional(\n",
    "                    true_labels, false_labels, current_informative_value)\n",
    "\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "        return best_quality, best_t, best_index\n",
    "\n",
    "    @staticmethod\n",
    "    def data_split(X, y, feature_idx, t):\n",
    "        left = (X[:, feature_idx] <= t)\n",
    "        true_data = X[left]\n",
    "        false_data = X[~left]\n",
    "        true_labels = y[left]\n",
    "        false_labels = y[~left]\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "    def tree_fit(self, X, y, subsample):\n",
    "        leaf_list = []\n",
    "        prediction_mask = {}\n",
    "        node_dict = {}\n",
    "        level = 0\n",
    "        data_id = 0\n",
    "        data_list = [[X, y, None, None, data_id]]\n",
    "        next_level_data = []\n",
    "        fl = 0\n",
    "\n",
    "        while not fl:\n",
    "            if level > 0:\n",
    "                data_list.clear()\n",
    "                data_list = next_level_data.copy()\n",
    "                next_level_data.clear()\n",
    "\n",
    "            for data in data_list:\n",
    "\n",
    "                best_quality, best_t, best_index = self.find_best_split(\n",
    "                    data[0], data[1], subsample)\n",
    "                if best_quality and (level <= self.max_depth):\n",
    "                    true_data, false_data, true_labels, false_labels = self.data_split(\n",
    "                        data[0], data[1], best_index, best_t)\n",
    "                    node_dict[data[4]] = [\n",
    "                        data[2], data[3], best_index, best_t]\n",
    "                    data_id += 1\n",
    "                    next_level_data.append(\n",
    "                        [true_data, true_labels, True, data[4], data_id])\n",
    "                    data_id += 1\n",
    "                    next_level_data.append(\n",
    "                        [false_data, false_labels, False, data[4], data_id])\n",
    "                else:\n",
    "                    leaf = self.get_label_num(data[1])\n",
    "                    prediction = max(leaf, key=leaf.get)\n",
    "                    proba = leaf[prediction] / len(data[0])\n",
    "                    if prediction == 0:\n",
    "                        proba = 1 - proba\n",
    "                    leaf_list.append(\n",
    "                        [data[2], data[3], proba, prediction])\n",
    "\n",
    "                level += 1\n",
    "\n",
    "            if not next_level_data:\n",
    "                fl = 1\n",
    "\n",
    "        for leaf in leaf_list:\n",
    "            mask = [(leaf[0], leaf[1])]\n",
    "            next_step = leaf[1]\n",
    "\n",
    "            while True:\n",
    "\n",
    "                if next_step is not None and next_step != 0:\n",
    "                    mask.append(\n",
    "                        (node_dict[next_step][0], node_dict[next_step][1]))\n",
    "                    next_step = node_dict[next_step][1]\n",
    "                else:\n",
    "                    mask.reverse()\n",
    "                    prediction_mask[tuple(mask)] = leaf[2], leaf[3]\n",
    "                    break\n",
    "        self.forest_list_to_predict.append([prediction_mask, node_dict])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        rdm = None\n",
    "        if self.random_state:\n",
    "            rng = np.random.RandomState(self.random_state)\n",
    "            rdm = rng.randint(1, 1000, self.n_trees)\n",
    "\n",
    "        for tree in range(self.n_trees):\n",
    "            r_state = rdm[tree] if self.random_state else self.random_state\n",
    "            idx = self.get_bootstrap_idx(n_samples, r_state)\n",
    "            self.oob_idx.append(list(set(range(n_samples)).difference(idx)))\n",
    "            subsample = self.get_subsample(n_features, r_state)\n",
    "            self.tree_fit(self.X[idx, :], self.y[idx], subsample)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        forest_proba = []\n",
    "        forest_pred = []\n",
    "        answer_mask_array = None\n",
    "        y_pred_proba = []\n",
    "\n",
    "        for n, tree in enumerate(self.forest_list_to_predict):\n",
    "            y_pred_proba_list = [None for _ in range(len(X_test))]\n",
    "\n",
    "            if self.oob_vote:  # oob\n",
    "                X_oob = self.X[self.oob_idx[n], :]\n",
    "                y_pred_oob = [None for i in range(len(X_oob))]\n",
    "                for mask in tree[0]:\n",
    "\n",
    "                    answer_mask = []\n",
    "                    predict_mask = [mask[i][0] for i in range(len(mask))]\n",
    "\n",
    "                    for question in mask:\n",
    "                        idx = tree[1][question[1]][2]\n",
    "                        t = tree[1][question[1]][3]\n",
    "                        y_pred_proba = [tree[0][mask]]\n",
    "                        answer_mask.append(X_oob[:, idx] <= t)\n",
    "                        answer_mask_array = np.array(answer_mask).T.tolist()\n",
    "\n",
    "                    for num, answer in enumerate(answer_mask_array):\n",
    "                        if answer == predict_mask and y_pred_proba_list[num] is None:\n",
    "                            y_pred_oob[num] = y_pred_proba\n",
    "                oob_prediction = np.array(y_pred_oob).reshape(-1, 2)[:, 1]\n",
    "                self.oob_scores_list.append(accuracy_score(self.y[self.oob_idx[n]], oob_prediction))\n",
    "\n",
    "            for mask in tree[0]:\n",
    "\n",
    "                answer_mask = []\n",
    "                predict_mask = [mask[i][0] for i in range(len(mask))]\n",
    "\n",
    "                for question in mask:\n",
    "                    idx = tree[1][question[1]][2]\n",
    "                    t = tree[1][question[1]][3]\n",
    "                    y_pred_proba = [tree[0][mask]]\n",
    "                    answer_mask.append(X_test[:, idx] <= t)\n",
    "                    answer_mask_array = np.array(answer_mask).T.tolist()\n",
    "\n",
    "                for num, answer in enumerate(answer_mask_array):\n",
    "                    if answer == predict_mask and y_pred_proba_list[num] is None:\n",
    "                        y_pred_proba_list[num] = y_pred_proba\n",
    "\n",
    "            prediction = np.array(y_pred_proba_list).reshape(-1, 2)[:, 1]\n",
    "            y_proba = np.array(y_pred_proba_list).reshape(-1, 2)[:, 0]\n",
    "            forest_proba.append(y_proba)\n",
    "            forest_pred.append(prediction)\n",
    "\n",
    "        self.forest_pred = np.array(forest_pred).T.reshape(X_test.shape[0], -1)\n",
    "        self.forest_proba = np.array(forest_proba).T.reshape(X_test.shape[0], -1)\n",
    "        if self.oob_vote:\n",
    "            vote_mask = (self.oob_scores_list >= np.quantile(self.oob_scores_list, self.oob_vote))\n",
    "            self.forest_proba = np.delete(self.forest_proba, vote_mask, axis=1)\n",
    "            self.forest_pred = np.delete(self.forest_pred, vote_mask, axis=1)\n",
    "\n",
    "        return mode(self.forest_pred, axis=1)[0].flatten(), np.mean(self.forest_proba, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
